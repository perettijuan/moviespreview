$schema: "http://json-schema.org/draft-06/schema#"

title: dataproc v1 SparkJob export schema
description: A gcloud export/import command YAML validation schema.
type: object
additionalProperties: false
properties:
  COMMENT:
    type: object
    description: User specified info ignored by gcloud import.
    additionalProperties: false
    properties:
      template-id:
        type: string
      region:
        type: string
      description:
        type: string
      date:
        type: string
      version:
        type: string
  UNKNOWN:
    type: array
    description: Unknown API fields that cannot be imported.
    items:
      type: string
  archiveUris:
    description: |-
      HCFS URIs of archives to be extracted in the working directory of Spark
      drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz, and
      .zip.
    type: array
    items:
      type: string
  args:
    description: |-
      The arguments to pass to the driver. Do not include arguments, such as
      --conf, that can be set as job properties, since a collision may occur
      that causes an incorrect job submission.
    type: array
    items:
      type: string
  fileUris:
    description: |-
      HCFS URIs of files to be copied to the working directory of Spark
      drivers and distributed tasks. Useful for naively parallel tasks.
    type: array
    items:
      type: string
  jarFileUris:
    description: |-
      HCFS URIs of jar files to add to the CLASSPATHs of the Spark
      driver and tasks.
    type: array
    items:
      type: string
  loggingConfig: {$ref: "LoggingConfig.yaml"}
  mainClass:
    description: |-
      The name of the driver's main class. The jar file that
      contains the class must be in the default CLASSPATH or
      specified in jar_file_uris.
    type: string
  mainJarFileUri:
    description: |-
      The HCFS URI of the jar file that contains the main class.
    type: string
  properties:
    description: |-
      A mapping of property names to values, used to configure
      Hadoop. Properties that conflict with values set by the
      Cloud Dataproc API may be overwritten. Can include
      properties set in /etc/hadoop/conf/*-site and classes in
      user code.
    type: object
    additionalProperties:
      description: |-
        Additional properties of type string
      type: string
